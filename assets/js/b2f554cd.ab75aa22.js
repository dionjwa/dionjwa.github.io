"use strict";(self.webpackChunkdionjwa_resume_docusaurus=self.webpackChunkdionjwa_resume_docusaurus||[]).push([[477],{10:e=>{e.exports=JSON.parse('{"blogPosts":[{"id":"/cloud-compute-cannon","metadata":{"permalink":"/blog/cloud-compute-cannon","source":"@site/blog/blog/cloud-compute-cannon.md","title":"Cloud Compute Cannon","description":"This was in 2017 at Autodesk Bionano (\u2192 Autodesk Lifesciences \u2192 shutdown), despite the date listed. This is more to record that I have been thinking and building on convenient, easy-access, standardized scalable compute for science for a while.","date":"2023-04-12T02:14:45.000Z","formattedDate":"April 12, 2023","tags":[],"hasTruncateMarker":false,"authors":[],"frontMatter":{"title":"Cloud Compute Cannon","sidebar_position":7,"slug":"/cloud-compute-cannon"},"nextItem":{"title":"Deno is part of the golden three","permalink":"/blog/deno-and-tool-ecosystems"}},"content":"> This was in 2017 at Autodesk Bionano (\u2192 Autodesk Lifesciences \u2192 `shutdown`), despite the date listed. This is more to record that I have been thinking and building on convenient, easy-access, standardized scalable compute for science for a while.\\n\\n\\n> Apart from the first paragraph, the rest is not applicable anymore, and the system is shelved.\\n\\n\\n> The [Bionano research group](http://bionano.autodesk.com/) at Autodesk needed an open source tool for performing scalable computes (e.g. molecular simulations) in the cloud. The problem it solves is _\\"I want to run 1000 simulations and get the results quickly, and I don\'t have access to a high performance cluster (or I don\'t know how to use the cluster)\\"_. We built [cloud-compute-cannon](https://github.com/Autodesk/cloudcomputecannon/) (CCC) for this. This blog describes some of the technology behind it.\\n\\n\\n### Architecture and technical decisions {#9c785c4f6b12478e978456f62b685acb}\\n\\n\\nCloud-compute-cannon is a client/server application. The server is installed on the users cloud (or their local machine) and creates workers to perform compute jobs. The server needs to:\\n\\n- Install locally and on cloud providers (e.g. AWS or GCE via their SDKs)\\n- Interact with Docker daemons via the remote API\\n- Interact with remote machines via SSH\\n- Talk to a database (that stores state)\\n- Interact with a thin CLI client\\n- Potentially other, as yet unknown, requirements\\n\\nInstead of worker machines pulling jobs from a queue, CCC works by pushing jobs to workers. The disadvantage with this approach is that if the servers goes down, the system stops working. The advantage is that the workers are extremely dumb: they are just bare CoreOS machines with nothing extra installed. Node.js can easily monitor many many workers in case they go down. By making the workers dumb, there is a single place for upgrading the system (simplicity was a goal here).\\n\\n\\n![](./743181975.png)\\n\\n\\nNode.js was a pretty easy choice for the server because of the large third party library support. Redis was chosen for the database because its simplicity and crucially, it had scripting support. Scripting means no concurrency issues as redis lua scripts block other requests.\\n\\n\\nThe added advantage of Node.js was using the same codebase for the client and server.\\n\\n\\nHowever, instead of writing Javascript, it was built in Haxe.\\n\\n\\n### What is [Haxe](https://haxe.org/#learn-more/)? {#29a6769c7e97428a9ac8af8ed423ea0f}\\n\\n\\n[Haxe](https://haxe.org/#learn-more/) is an open source language and toolkit. The language is inspired from Javascript and Actionscript (Flash). The Haxe toolkit has _multiple compilers_, meaning you write in one language, and you export directly to multiple languages:\\n\\n\\nCurrently, Haxe compiles to the following targets:\\n\\n\\n![https://haxe.org/documentation/introduction/compiler-targets.html](./850217860.png)\\n\\n\\nFor this project though, we\'re using just the Javascript compiler. Why Haxe and not e.g. Coffeescript or Typescript (or plain Javascript)? A more detailed answer is provided by [Andy Li](http://blog.onthewings.net/2015/08/05/typescript-vs-haxe/), but in short: Haxe provides far more useful language features, and it is more mature, and has compile time type checking that is invaluable in large code-bases. It has the added bonus that we could build multiple clients in different languages (e.g. Python or native binaries) if needed (the server would be more difficult due to the reliance on third party libraries).\\n\\n\\nAlthough Haxe has many [very useful language features](http://haxe.org/manual/lf.html), the features most important to this project are:\\n\\n\\n### 1) Compile time typing {#efe9c56b642e42e3a9345cc92653e527}\\n\\n\\nFunctions, collections, and variables are _typed_, and checked at compile time. For example, the compiler will prevent you from calling a function with an Int argument when it\'s expecting an array. For a large-ish codebase of a cloud application this is crucial, as it reduces the number of bugs that make it into functional testing (and functional testing scalable cloud applications is _very_ time consuming).\\n\\n\\nJavascript code. Note you can call a function with whatever arguments you like:\\n\\n\\n```javascript\\nclass Foo\\n{\\n\\tconstructor() {}\\n\\n\\tdoAThing(input)\\n\\t{\\n\\t\\treturn [input, input + 5];\\n\\t}\\n}\\n\\n//Somewhere else:\\nvar foo = new Foo();\\nvar result = foo.doAThing(10); //This is correct\\nvar result2 = foo.doAThing(\\"somestring\\"); //Legal, although bad.\\n```\\n\\n\\nIn Haxe, you cannot compile with the last line. The compiler has caught a mistake the developer wrote.\\n\\n\\n```javascript\\n//Haxe\\nclass Foo\\n{\\n\\tpublic function new() {}\\n\\n\\tpublic function doAThing(input :Int) :Array<Int>\\n\\t{\\n\\t\\treturn [input, input + 5];\\n\\t}\\n}\\n// Somewhere else:\\nvar foo = new Foo();\\nvar result = foo.doAThing(10); //This is correct\\nvar result2 = foo.doAThing(\\"somestring\\"); //Compile error!\\n\\n```\\n\\n\\n### 2) Macros {#856c6b2496904f3195522a9b7bd53c3d}\\n\\n\\nHaxe macros are incredibly powerful, and the full capabilities are beyond the scope of this blog post. For this project they automatically generate bindings between the CLI client and the server.\\n\\n\\nOn the server, there are \'services\' where the methods correspond to RPC (remote procedure calls), where the **@rpc** decorator marks it as a remote API endpoint:\\n\\n\\n```javascript\\nclass ServiceBatchCompute\\n{\\n\\t//Server method for an API endpoint:\\n\\t@rpc({alias: \'jobs\', doc: \'List all job ids\'})\\n\\tpublic function jobs() :Promise<Array<JobId>>\\n\\t{\\n\\t\\treturn ComputeQueue.getAllJobIds(_redis);\\n\\t}\\n}\\n```\\n\\n\\nOn the client\\n\\n\\n```javascript\\n//Server methods\\nvar defs = Macros.getMethodDefinitions(ServiceBatchCompute);\\nfor(def in defs) {\\n\\tCommanderTools.addCommand(program, def);\\n}\\n```\\n\\n\\nThe above code generates (at compile time) a function that creates a [JSON-RPC](https://en.wikipedia.org/wiki/JSON-RPC) call to the remote server if the CLI command is called. E.g. calling the CLI client with the **jobs** sub-command:\\n\\n\\n```shell\\nccc jobs\\n```\\n\\n\\ncreates the following JSON and sends it to the server (via http):\\n\\n\\n```javascript\\n{\\n\\tjsonrpc:\\"2.0\\",\\n\\tid: \\"_\\",\\n\\tmethod: \\"jobs\\",\\n\\tparams: {}\\n}\\n```\\n\\n\\nThe server maps the call to the correct function, calls the function, then sends the result back in the HTTP response. The CLI interacts with the server API, but it could easily be another server.\\n\\n\\nThe important point is that new services have the corresponding CLI client commands _automatically_ generated. There is no need to touch the client code ever again, and there is no chance that a typo will accidentally break client-server communication.\\n\\n\\n### 3) Code completion {#c82fb9fb390144bca575dfc8f12c6551}\\n\\n\\nI just really like code completion. Code completion is handled by the Haxe compiler, so all text editors and IDEs can easily add sophisticated code completion.\\n\\n\\n![](./595463753.png)\\n\\n\\n### 4) Abstracts {#4bb9b6ad68d04f49a1e1d7611abcba8d}\\n\\n\\nThese are classes and data structures that do not exist at run-time, only at compile time. In Cloud-compute-cannon, they are used to maintain specific compile-checked enum types between the server and the database scripts.\\n\\n\\nThe redis scripts are in Lua, which is a new Haxe target! However the Lua target is not yet mature, so the database scripts are written manually, and embedded as raw strings in Haxe classes. This has the advantage of some compile time checking of constants and abstract types.\\n\\n\\nThe following is a [Haxe abstract enum](http://haxe.org/manual/types-abstract-enum.html). It only exists at compile time, at runtime the values are just strings.\\n\\n\\n```javascript\\n@:enum\\nabstract JobStatus(String) from String {\\n\\tvar Pending = \'pending\';\\n\\tvar Working = \'working\';\\n\\tvar Finalizing = \'finalizing\';\\n\\tvar Finished = \'finished\';\\n}\\n```\\n\\n\\nHowever, the values can be embedded in a Lua script:\\n\\n\\n```lua\\nlocal status = \\"${JobStatus.Pending}\\"\\n```\\n\\n\\nAnd this Lua script is embedded in a Haxe class (this example is contrived for simplicity):\\n\\n\\n```javascript\\nvar script = \'local status = \\"${JobStatus.Pending}\\"\';\\n```\\n\\n\\nThen if we change the JobStatus abstract, all the values are compile time checked. This means that it is impossible for a simple typo in a string value to result in a value being sent between the server and the database.\\n\\n\\nWhen the Lua target stabilizes, the scripts may get written in Haxe and compiled. This would allow better code re-use, and allow compile-time checking of the actual types and objects being created, stored, and send from within the database.\\n\\n\\n### Conclusion {#84f4acf04a7f43eba3481ae98c1cfa96}\\n\\n\\nThis demonstrates some of the power that the Haxe toolkit provides:\\n\\n- Flexibility: write code for multiple platforms without losing the power of a compiler.\\n- Future proofing: as new platforms become available, the Haxe toolkit can target them.\\n- More robust code: compiler prevent simple errors, and make maintenance (e.g. refactoring) of large code bases much easier.\\n- Performance: function inline may not available on the target platform itself (e.g. Javascript in Node.js)."},{"id":"/deno-and-tool-ecosystems","metadata":{"permalink":"/blog/deno-and-tool-ecosystems","source":"@site/blog/blog/deno-and-tool-ecosystems.md","title":"Deno is part of the golden three","description":"","date":"2023-04-12T02:14:45.000Z","formattedDate":"April 12, 2023","tags":[],"hasTruncateMarker":false,"authors":[],"frontMatter":{"title":"Deno is part of the golden three","sidebar_position":1,"slug":"/deno-and-tool-ecosystems"},"prevItem":{"title":"Cloud Compute Cannon","permalink":"/blog/cloud-compute-cannon"},"nextItem":{"title":"Docker and wasm","permalink":"/blog/docker-wasm-web-containers"}},"content":"```mermaid\\nflowchart LR\\n    subgraph g [golden three]\\n        direction LR\\n        j[justfiles]\\n        d[deno]\\n        docker[docker]\\n        j --\x3e d --\x3e docker --\x3e j\\n    end\\n  click j \\"/blog/one-justfile-to-bind-them-all\\"\\n  click d \\"/blog/deno-and-tool-ecosystems\\"\\n  click docker \\"/blog/docker-wasm-web-containers\\"\\n```"},{"id":"/docker-wasm-web-containers","metadata":{"permalink":"/blog/docker-wasm-web-containers","source":"@site/blog/blog/docker-wasm-web-containers.md","title":"Docker and wasm","description":"","date":"2023-04-12T02:14:45.000Z","formattedDate":"April 12, 2023","tags":[],"hasTruncateMarker":false,"authors":[],"frontMatter":{"title":"Docker and wasm","sidebar_position":2,"slug":"/docker-wasm-web-containers"},"prevItem":{"title":"Deno is part of the golden three","permalink":"/blog/deno-and-tool-ecosystems"},"nextItem":{"title":"How this blog is automated","permalink":"/blog/how-this-blog-is-automated"}},"content":"```mermaid\\nflowchart LR\\n    subgraph g [golden three]\\n        direction LR\\n        j[justfiles]\\n        d[deno]\\n        docker[docker]\\n        j --\x3e d --\x3e docker --\x3e j\\n    end\\n  click j \\"/blog/one-justfile-to-bind-them-all\\"\\n  click d \\"/blog/deno-and-tool-ecosystems\\"\\n  click docker \\"/blog/docker-wasm-web-containers\\"\\n```"},{"id":"/how-this-blog-is-automated","metadata":{"permalink":"/blog/how-this-blog-is-automated","source":"@site/blog/blog/how-this-blog-is-automated.md","title":"How this blog is automated","description":"1. I write blog posts in notion, structured how I like","date":"2023-04-12T02:14:45.000Z","formattedDate":"April 12, 2023","tags":[],"hasTruncateMarker":false,"authors":[],"frontMatter":{"title":"How this blog is automated","sidebar_position":3,"slug":"/how-this-blog-is-automated"},"prevItem":{"title":"Docker and wasm","permalink":"/blog/docker-wasm-web-containers"},"nextItem":{"title":"Justfiles - universal command control","permalink":"/blog/one-justfile-to-bind-them-all"}},"content":"1. I write blog posts in [notion](https://notion.so), structured how I like\\n1. Automatically ~15 minutes later the website + blog is generated from notion, using [docusaurus](https://docusaurus.io/) + [docu-notion](https://github.com/sillsdev/docu-notion), and pushed to github pages\\n1. ~~There\u2019s nothing I actually needed to do except write~~\\n\\nThat\u2019s it. I just write. The rest is automated.\\n\\n\\n### How it works {#1900a1e531c64d3ab4896817eefc7eba}\\n\\n\\nSource: [https://github.com/dionjwa/dionjwa.github.io](https://github.com/dionjwa/dionjwa.github.io)\\n\\n\\n```mermaid\\nflowchart LR\\n    subgraph gh [github action every 30m]\\n        direction LR\\n        db[(notion.so)] --\x3e D[docu-notion]\\n        D --\x3e ds(docusaurus)\\n        ds --\x3e deploy[deploy to github pages ]\\n\\n    end\\n  \\n  click D https://github.com/sillsdev/docu-notion\\n  click ds https://docusaurus.io/\\n  click db https://www.notion.so\\n```\\n\\n\\nA github action runs a few scripts commands:\\n\\n1. Using [docu-notion](https://github.com/sillsdev/docu-notion) (and a root notion page) the docusaurus blog markdown is generated from specified notion pages\\n1. The docusaurus website is built\\n1. Then deployed to github pages\\n\\nIt\u2019s otherwise tricky to find a set of tools for writing/publishing a blog+resume with the following requirements (for me):\\n\\n- open source, or high data trust\\n- able to output from notion. I\u2019m too tired to convert to anything, like multiple publishing endpoints. I just want to write, and have everything be automated\\n- but also look good\\n- where i just write, and do absolutely nothing else. no saving, no publishing step.\\n- but also everything is backed up, with full version history"},{"id":"/one-justfile-to-bind-them-all","metadata":{"permalink":"/blog/one-justfile-to-bind-them-all","source":"@site/blog/blog/one-justfile-to-bind-them-all.md","title":"Justfiles - universal command control","description":"Just Words of Wisdom (To Myself)","date":"2023-04-12T02:14:45.000Z","formattedDate":"April 12, 2023","tags":[],"hasTruncateMarker":false,"authors":[],"frontMatter":{"title":"Justfiles - universal command control","sidebar_position":0,"slug":"/one-justfile-to-bind-them-all"},"prevItem":{"title":"How this blog is automated","permalink":"/blog/how-this-blog-is-automated"},"nextItem":{"title":"Publications","permalink":"/blog/publications"}},"content":"```mermaid\\nflowchart LR\\n    subgraph g [golden three]\\n        direction LR\\n        j[justfiles]\\n        d[deno]\\n        docker[docker]\\n        j --\x3e d --\x3e docker --\x3e j\\n    end\\n  click j \\"/blog/one-justfile-to-bind-them-all\\"\\n  click d \\"/blog/deno-and-tool-ecosystems\\"\\n  click docker \\"/blog/docker-wasm-web-containers\\"\\n```\\n\\n\\n\\n## Just Words of Wisdom (To Myself) {#a660199f26954368939f6ff59ee255ae}\\n\\n\\n### Always include the full path of commands {#d2d23cebe20b4d158daa8400e3cdf9ac}\\n\\n\\nIf you document something with what &lt;command&gt; you should run, e.g.\\n\\n\\n```bash\\n# And then you type: \'just <command>\'\\n```\\n\\n\\nbut you are `</over/here>` but you have to be `</somewhere/else>` then please include the full path so there is never any doubt and you don\u2019t have to go `fd`\'ing: `\'</be/specific> just <command>\'`. It doesn\u2019t have to be this exact formula, but try to remove this kind of friction."},{"id":"/publications","metadata":{"permalink":"/blog/publications","source":"@site/blog/blog/publications.md","title":"Publications","description":"Academic Publications (2004 - 2008)","date":"2023-04-12T02:14:45.000Z","formattedDate":"April 12, 2023","tags":[],"hasTruncateMarker":false,"authors":[],"frontMatter":{"title":"Publications","sidebar_position":5,"slug":"/publications"},"prevItem":{"title":"Justfiles - universal command control","permalink":"/blog/one-justfile-to-bind-them-all"},"nextItem":{"title":"Entire Resume for Printing","permalink":"/blog/resume-complete"}},"content":"## Academic Publications (2004 - 2008)\\n- [The look-ahead effect of phenotypic mutations.](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2423361/). D. Whitehead, Claus Wilke, D. Vernazobres\\nand E. Bornberg-Bauer. *Biology Direct * (2008).\\n- [The AtGenExpress global stress expression data set: Protocols, evaluation and model data analysis of UV-B light, drought and cold stress responses.](http://www.blackwell-synergy.com/doi/abs/10.1111/j.1365-313X.2007.03052.x) J. Kilian, D. Whitehead, J. Horak, D.\\nWanke, S. Weinl, O. Batistic, C. D\'Angelo, E. Bornberg-Bauer, J. Kudla and K. Harter. _Plant J_ (2007).\\n- [Chapter 13: Evolution of Regulatory Networks, Systems Biology Applied to Toxicogenomics.](http://www.worldscibooks.com/lifesci/6459.html) Amelie Veron, Dion Whitehead, et. el Fran\xe7ois K\xe9p\xe8s (ed.). _World Scientific_ (2007).\\n- [Reconstructing gene function and gene regulatory networks in prokaryotes.](http://bieson.ub.uni-bielefeld.de/volltexte/2005/792) Dion Whitehead. _PhD Thesis_ (2005).\\n- [Handbook of Toxicogenomics: Strategies and Applications 13: Systems Biology Applied to Toxicogenomics.](http://www3.interscience.wiley.com/cgi-bin/abstract/110575170/ABSTRACT) Klaus Prank, Matthias Hoechsmann, Bjoern Oleson, Thomas Schmidt, Leila Taher, Dion Whitehead, J\xfcrgen Borlak (ed.). _John Wiley & Sons_ (2005).\\n- [Evaluating an Evolutionary Approach for Reconstructing Gene Regulatory Networks.](https://www.researchgate.net/publication/237005333_Evaluating_an_Evolutionary_Approach_for_Reconstructing_Gene_Regulatory_Networks) Whitehead, D. and Skusa, A. and Kennedy, P.J. _Ninth International Conference on the Simulation and\\nSynthesis of Living Systems_ (2004).\\n\\n\\n\\n## Academic Publications (2004 - 2008)\\n\\n- [The look-ahead effect of phenotypic mutations.](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2423361/). D. Whitehead, Claus Wilke, D. Vernazobres\\nand E. Bornberg-Bauer. *Biology Direct * (2008).\\n- [The AtGenExpress global stress expression data set: Protocols, evaluation and model data analysis of UV-B light, drought and cold stress responses.](http://www.blackwell-synergy.com/doi/abs/10.1111/j.1365-313X.2007.03052.x) J. Kilian, D. Whitehead, J. Horak, D.\\nWanke, S. Weinl, O. Batistic, C. D\'Angelo, E. Bornberg-Bauer, J. Kudla and K. Harter. _Plant J_ (2007).\\n- [Chapter 13: Evolution of Regulatory Networks, Systems Biology Applied to Toxicogenomics.](http://www.worldscibooks.com/lifesci/6459.html) Amelie Veron, Dion Whitehead, et. el Fran\xe7ois K\xe9p\xe8s (ed.). _World Scientific_ (2007).\\n- [Reconstructing gene function and gene regulatory networks in prokaryotes.](http://bieson.ub.uni-bielefeld.de/volltexte/2005/792) Dion Whitehead. _PhD Thesis_ (2005).\\n- [Handbook of Toxicogenomics: Strategies and Applications 13: Systems Biology Applied to Toxicogenomics.](http://www3.interscience.wiley.com/cgi-bin/abstract/110575170/ABSTRACT) Klaus Prank, Matthias Hoechsmann, Bjoern Oleson, Thomas Schmidt, Leila Taher, Dion Whitehead, J\xfcrgen Borlak (ed.). _John Wiley & Sons_ (2005).\\n- [Evaluating an Evolutionary Approach for Reconstructing Gene Regulatory Networks.](https://www.researchgate.net/publication/237005333_Evaluating_an_Evolutionary_Approach_for_Reconstructing_Gene_Regulatory_Networks) Whitehead, D. and Skusa, A. and Kennedy, P.J. _Ninth International Conference on the Simulation and\\nSynthesis of Living Systems_ (2004)."},{"id":"/resume-complete","metadata":{"permalink":"/blog/resume-complete","source":"@site/blog/blog/resume-complete.md","title":"Entire Resume for Printing","description":"Academic Publications (2004 - 2008)","date":"2023-04-12T02:14:45.000Z","formattedDate":"April 12, 2023","tags":[],"hasTruncateMarker":false,"authors":[],"frontMatter":{"title":"Entire Resume for Printing","sidebar_position":6,"slug":"/resume-complete"},"prevItem":{"title":"Publications","permalink":"/blog/publications"},"nextItem":{"title":"Resume","permalink":"/blog/resume"}},"content":"## Academic Publications (2004 - 2008)\\n- [The look-ahead effect of phenotypic mutations.](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2423361/). D. Whitehead, Claus Wilke, D. Vernazobres\\nand E. Bornberg-Bauer. *Biology Direct * (2008).\\n- [The AtGenExpress global stress expression data set: Protocols, evaluation and model data analysis of UV-B light, drought and cold stress responses.](http://www.blackwell-synergy.com/doi/abs/10.1111/j.1365-313X.2007.03052.x) J. Kilian, D. Whitehead, J. Horak, D.\\nWanke, S. Weinl, O. Batistic, C. D\'Angelo, E. Bornberg-Bauer, J. Kudla and K. Harter. _Plant J_ (2007).\\n- [Chapter 13: Evolution of Regulatory Networks, Systems Biology Applied to Toxicogenomics.](http://www.worldscibooks.com/lifesci/6459.html) Amelie Veron, Dion Whitehead, et. el Fran\xe7ois K\xe9p\xe8s (ed.). _World Scientific_ (2007).\\n- [Reconstructing gene function and gene regulatory networks in prokaryotes.](http://bieson.ub.uni-bielefeld.de/volltexte/2005/792) Dion Whitehead. _PhD Thesis_ (2005).\\n- [Handbook of Toxicogenomics: Strategies and Applications 13: Systems Biology Applied to Toxicogenomics.](http://www3.interscience.wiley.com/cgi-bin/abstract/110575170/ABSTRACT) Klaus Prank, Matthias Hoechsmann, Bjoern Oleson, Thomas Schmidt, Leila Taher, Dion Whitehead, J\xfcrgen Borlak (ed.). _John Wiley & Sons_ (2005).\\n- [Evaluating an Evolutionary Approach for Reconstructing Gene Regulatory Networks.](https://www.researchgate.net/publication/237005333_Evaluating_an_Evolutionary_Approach_for_Reconstructing_Gene_Regulatory_Networks) Whitehead, D. and Skusa, A. and Kennedy, P.J. _Ninth International Conference on the Simulation and\\nSynthesis of Living Systems_ (2004)."},{"id":"/resume","metadata":{"permalink":"/blog/resume","source":"@site/blog/blog/resume.md","title":"Resume","description":"","date":"2023-04-12T02:14:45.000Z","formattedDate":"April 12, 2023","tags":[],"hasTruncateMarker":false,"authors":[],"frontMatter":{"title":"Resume","sidebar_position":8,"slug":"/resume"},"prevItem":{"title":"Entire Resume for Printing","permalink":"/blog/resume-complete"},"nextItem":{"title":"The golden trifecta- justfiles, deno, and docker","permalink":"/blog/the-golden-three-just-deno-docker"}},"content":""},{"id":"/the-golden-three-just-deno-docker","metadata":{"permalink":"/blog/the-golden-three-just-deno-docker","source":"@site/blog/blog/the-golden-three-just-deno-docker.md","title":"The golden trifecta- justfiles, deno, and docker","description":"","date":"2023-04-12T02:14:45.000Z","formattedDate":"April 12, 2023","tags":[],"hasTruncateMarker":false,"authors":[],"frontMatter":{"title":"The golden trifecta- justfiles, deno, and docker","sidebar_position":4,"slug":"/the-golden-three-just-deno-docker"},"prevItem":{"title":"Resume","permalink":"/blog/resume"}},"content":"```mermaid\\nflowchart LR\\n    subgraph g [golden three]\\n        direction LR\\n        j[justfiles]\\n        d[deno]\\n        docker[docker]\\n        j --\x3e d --\x3e docker --\x3e j\\n    end\\n  click j \\"/blog/one-justfile-to-bind-them-all\\"\\n  click d \\"/blog/deno-and-tool-ecosystems\\"\\n  click docker \\"/blog/docker-wasm-web-containers\\"\\n```"}]}')}}]);